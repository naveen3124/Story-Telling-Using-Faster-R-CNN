{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PREPROCESSED_PATH = \"E:\\Projects\\Story-Telling-Using-Show-Attend-and-tell\"\n",
    "\n",
    "def preProBuildWordVocab(sentence_iterator, word_count_threshold=5):\n",
    "    # borrowed this function from NeuralTalk\n",
    "    print ('preprocessing word counts and creating vocab based on word count threshold %d' % (word_count_threshold, ))\n",
    "\n",
    "    word_counts = {}\n",
    "    nsents = 0\n",
    "\n",
    "    for sent in sentence_iterator:\n",
    "        nsents += 1\n",
    "        tmp_sent = sent.lower().split(' ')\n",
    "        if '' in tmp_sent:\n",
    "            tmp_sent.remove('')\n",
    "\n",
    "        for w in tmp_sent:\n",
    "           word_counts[w] = word_counts.get(w, 0) + 1\n",
    "\n",
    "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "    print ('filtered words from %d to %d' % (len(word_counts), len(vocab)))\n",
    "\n",
    "    ixtoword = {}\n",
    "    ixtoword[0] = '<bos>'\n",
    "    ixtoword[1] = '<eos>'\n",
    "    ixtoword[2] = '<pad>'\n",
    "    ixtoword[3] = '<unk>'\n",
    "\n",
    "    wordtoix = {}\n",
    "    wordtoix['<bos>'] = 0\n",
    "    wordtoix['<eos>'] = 1\n",
    "    wordtoix['<pad>'] = 2\n",
    "    wordtoix['<unk>'] = 3\n",
    "\n",
    "    for idx, w in enumerate(vocab):\n",
    "        wordtoix[w] = idx + 4\n",
    "        ixtoword[idx+4] = w\n",
    "\n",
    "    word_counts['<eos>'] = nsents\n",
    "    word_counts['<bos>'] = nsents\n",
    "    word_counts['<pad>'] = nsents\n",
    "    word_counts['<unk>'] = nsents\n",
    "\n",
    "    bias_init_vector = np.array([1.0 * word_counts[ ixtoword[i] ] for i in ixtoword])\n",
    "    bias_init_vector /= np.sum(bias_init_vector) # normalize to frequencies\n",
    "    bias_init_vector = np.log(bias_init_vector)\n",
    "    bias_init_vector -= np.max(bias_init_vector) # shift to nice numeric range\n",
    "\n",
    "    return wordtoix, ixtoword, bias_init_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing word counts and creating vocab based on word count threshold 2\n",
      "filtered words from 18926 to 9933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "batch_size = 50 # Being support batch_size\n",
    "num_boxes = 50 # number of Detected regions in each image\n",
    "feats_dim = 4096 # feature dimensions of each regions\n",
    "project_dim = 1024 # project the features to one vector, which is 1024 dimensions\n",
    "\n",
    "sentRNN_lstm_dim = 512 # the sentence LSTM hidden units\n",
    "sentRNN_FC_dim = 1024 # the fully connected units\n",
    "wordRNN_lstm_dim = 512 # the word LSTM hidden units\n",
    "word_embed_dim = 1024 # the learned embedding vectors for the words\n",
    "\n",
    "S_max = 6\n",
    "N_max = 30\n",
    "T_stop = 0.5\n",
    "\n",
    "n_epochs = 500\n",
    "learning_rate = 0.0001\n",
    "\n",
    "open(PREPROCESSED_PATH+'\\genomedata\\paragraphs_v1.json').read()\n",
    "\n",
    "img2paragraph = pickle.load(open(PREPROCESSED_PATH+ '\\img2paragraph','rb'))\n",
    "all_sentences = []\n",
    "for key, paragraph in img2paragraph.items():\n",
    "    for each_sent in paragraph[1]:\n",
    "        each_sent.replace(',', ' ,')\n",
    "        all_sentences.append(each_sent)\n",
    "word2idx, idx2word, bias_init_vector = preProBuildWordVocab(all_sentences, word_count_threshold=2)\n",
    "np.save(PREPROCESSED_PATH +'\\idx2word_batch', idx2word)\n",
    "\n",
    "img2paragraph_modify = {}\n",
    "for img_name, img_paragraph in img2paragraph.items():\n",
    "    img_paragraph_1 = img_paragraph[1]\n",
    "\n",
    "    if '' in img_paragraph_1:\n",
    "        img_paragraph_1.remove('')\n",
    "    if ' ' in paragraph[1]:\n",
    "        img_paragraph_1.remove(' ')   \n",
    "    img_num_sents = len(img_paragraph_1)\n",
    "    if img_num_sents > S_max:\n",
    "        img_num_sents = S_max\n",
    "    img_num_distribution = np.zeros([S_max], dtype=np.int32)\n",
    "    img_num_distribution[img_num_sents-1:] = 1\n",
    "\n",
    "    img_captions_matrix = np.ones([S_max, N_max+1], dtype=np.int32) * 2 # zeros([6, 50])\n",
    "    for idx, img_sent in enumerate(img_paragraph_1):\n",
    "        # the number of sentences is img_num_sents\n",
    "        if idx == img_num_sents:\n",
    "            break\n",
    "\n",
    "        # because we treat the ',' as a word\n",
    "        img_sent = img_sent.replace(',', ' ,')\n",
    "\n",
    "       \n",
    "        if len(img_sent)>=3 and img_sent[0] == ' ' and img_sent[1] != ' ':\n",
    "            img_sent = img_sent[1:]\n",
    "        elif len(img_sent)>=3 and img_sent[0] == ' ' and img_sent[1] == ' ' and img_sent[2] != ' ':\n",
    "            img_sent = img_sent[2:]\n",
    "\n",
    "        # Be careful the last part in a sentence, like this:\n",
    "        # '...world.'\n",
    "        # '...world. '\n",
    "        if len(img_sent)>=1 and img_sent[-1] == '.':\n",
    "            img_sent = img_sent[0:-1]\n",
    "        elif len(img_sent)>=2 and img_sent[-1] == ' ' and img_sent[-2] == '.':\n",
    "            img_sent = img_sent[0:-2]\n",
    "\n",
    "        # Last, we add the <bos> and the <eos> in each sentences\n",
    "        img_sent = '<bos> ' + img_sent + ' <eos>'\n",
    "\n",
    "        for idy, word in enumerate(img_sent.lower().split(' ')):\n",
    "            # because the biggest number of words in a sentence is N_max, here is 50\n",
    "            if idy == N_max:\n",
    "                break\n",
    "\n",
    "            if word in word2idx:\n",
    "                img_captions_matrix[idx, idy] = word2idx[word]\n",
    "            else:\n",
    "                img_captions_matrix[idx, idy] = word2idx['<unk>']\n",
    "\n",
    "    img2paragraph_modify[str(img_name)] = [img_num_distribution, img_captions_matrix]\n",
    "with open(PREPROCESSED_PATH+ '\\img2paragraph_modify_batch', 'wb') as f:\n",
    "    pickle.dump(img2paragraph_modify, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionPooling_HierarchicalRNN():\n",
    "    def __init__(self, n_words,\n",
    "                       batch_size,\n",
    "                       num_boxes,\n",
    "                       feats_dim,\n",
    "                       project_dim,\n",
    "                       sentRNN_lstm_dim,\n",
    "                       sentRNN_FC_dim,\n",
    "                       wordRNN_lstm_dim,\n",
    "                       S_max,\n",
    "                       N_max,\n",
    "                       word_embed_dim,\n",
    "                       bias_init_vector=None):\n",
    "\n",
    "        self.n_words = n_words\n",
    "        self.batch_size = batch_size\n",
    "        self.num_boxes = num_boxes # 50\n",
    "        self.feats_dim = feats_dim # 4096\n",
    "        self.project_dim = project_dim # 1024\n",
    "        self.S_max = S_max # 6\n",
    "        self.N_max = N_max # 50\n",
    "        self.word_embed_dim = word_embed_dim # 1024\n",
    "\n",
    "        self.sentRNN_lstm_dim = sentRNN_lstm_dim # 512 hidden size\n",
    "        self.sentRNN_FC_dim = sentRNN_FC_dim # 1024 in fully connected layer\n",
    "        self.wordRNN_lstm_dim = wordRNN_lstm_dim # 512 hidden size\n",
    "\n",
    "        # word embedding, parameters of embedding\n",
    "        # embedding shape: n_words x wordRNN_lstm_dim\n",
    "        with tf.device('/cpu:0'):\n",
    "            self.Wemb = tf.Variable(tf.random_uniform([n_words, word_embed_dim], -0.1, 0.1), name='Wemb')\n",
    "        #self.bemb = tf.Variable(tf.zeros([word_embed_dim]), name='bemb')\n",
    "\n",
    "        # regionPooling_W shape: 4096 x 1024\n",
    "        # regionPooling_b shape: 1024\n",
    "        self.regionPooling_W = tf.Variable(tf.random_uniform([feats_dim, project_dim], -0.1, 0.1), name='regionPooling_W')\n",
    "        self.regionPooling_b = tf.Variable(tf.zeros([project_dim]), name='regionPooling_b')\n",
    "\n",
    "        # sentence LSTM\n",
    "        self.sent_LSTM = tf.nn.rnn_cell.BasicLSTMCell(sentRNN_lstm_dim, state_is_tuple=True)\n",
    "\n",
    "        # logistic classifier\n",
    "        self.logistic_Theta_W = tf.Variable(tf.random_uniform([sentRNN_lstm_dim, 2], -0.1, 0.1), name='logistic_Theta_W')\n",
    "        self.logistic_Theta_b = tf.Variable(tf.zeros(2), name='logistic_Theta_b')\n",
    "\n",
    "        # fc1_W: 512 x 1024, fc1_b: 1024\n",
    "        # fc2_W: 1024 x 1024, fc2_b: 1024\n",
    "        self.fc1_W = tf.Variable(tf.random_uniform([sentRNN_lstm_dim, sentRNN_FC_dim], -0.1, 0.1), name='fc1_W')\n",
    "        self.fc1_b = tf.Variable(tf.zeros(sentRNN_FC_dim), name='fc1_b')\n",
    "        self.fc2_W = tf.Variable(tf.random_uniform([sentRNN_FC_dim, 1024], -0.1, 0.1), name='fc2_W')\n",
    "        self.fc2_b = tf.Variable(tf.zeros(1024), name='fc2_b')\n",
    "\n",
    "        # word LSTM\n",
    "        self.word_LSTM = tf.nn.rnn_cell.BasicLSTMCell(wordRNN_lstm_dim, state_is_tuple=True)\n",
    "        self.word_LSTM = tf.nn.rnn_cell.MultiRNNCell([self.word_LSTM,self.word_LSTM], state_is_tuple=True)\n",
    "        self.word_LSTM = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.BasicLSTMCell(wordRNN_lstm_dim,state_is_tuple=True) for _ in range(2)])\n",
    "\n",
    "        self.embed_word_W = tf.Variable(tf.random_uniform([wordRNN_lstm_dim, n_words], -0.1,0.1), name='embed_word_W')\n",
    "        if bias_init_vector is not None:\n",
    "            self.embed_word_b = tf.Variable(bias_init_vector.astype(np.float32), name='embed_word_b')\n",
    "            self.embed_word_b = tf.Variable(tf.zeros([n_words]), name='embed_word_b')\n",
    "    def build_model(self):\n",
    "       \n",
    "        feats = tf.placeholder(tf.float32, [self.batch_size, self.num_boxes, self.feats_dim])\n",
    "        tmp_feats = tf.reshape(feats, [-1, self.feats_dim])\n",
    "\n",
    "      \n",
    "        project_vec_all = tf.matmul(tmp_feats, self.regionPooling_W) + self.regionPooling_b\n",
    "        project_vec_all = tf.reshape(project_vec_all, [self.batch_size, 50, self.project_dim])\n",
    "        project_vec = tf.reduce_max(project_vec_all, reduction_indices=1)\n",
    "\n",
    "        \n",
    "        num_distribution = tf.placeholder(tf.int32, [self.batch_size, self.S_max])\n",
    "\n",
    "        captions = tf.placeholder(tf.int32, [self.batch_size, self.S_max, self.N_max+1])\n",
    "        captions_masks = tf.placeholder(tf.float32, [self.batch_size, self.S_max, self.N_max+1])\n",
    "\n",
    "        \n",
    "        sent_state = self.sent_LSTM.zero_state(batch_size=self.batch_size, dtype=tf.float32)\n",
    "       \n",
    "\n",
    "        probs = []\n",
    "        loss = 0.0\n",
    "        loss_sent = 0.0\n",
    "        loss_word = 0.0\n",
    "        lambda_sent = 5.0\n",
    "        lambda_word = 1.0\n",
    "\n",
    "        print ('Start build model:')\n",
    "        \n",
    "        for i in range(0, self.S_max):\n",
    "            print(\"naveen\")\n",
    "            if i > 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "            with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
    "                sent_output, sent_state = self.sent_LSTM(project_vec, sent_state)\n",
    "\n",
    "            with tf.name_scope('fc1'):\n",
    "                hidden1 = tf.nn.relu( tf.matmul(sent_output, self.fc1_W) + self.fc1_b )\n",
    "            with tf.name_scope('fc2'):\n",
    "                sent_topic_vec = tf.nn.relu( tf.matmul(hidden1, self.fc2_W) + self.fc2_b )\n",
    "\n",
    "           \n",
    "            sentRNN_logistic_mu = tf.nn.xw_plus_b( sent_output, self.logistic_Theta_W, self.logistic_Theta_b )\n",
    "            sentRNN_label = tf.stack([ 1 - num_distribution[:, i], num_distribution[:, i] ])\n",
    "            sentRNN_label = tf.transpose(sentRNN_label)\n",
    "            # https://github.com/ibab/tensorflow-wavenet/issues/223\n",
    "            sentRNN_loss = tf.nn.softmax_cross_entropy_with_logits(labels=sentRNN_label, logits=sentRNN_logistic_mu)\n",
    "            sentRNN_loss = tf.reduce_sum(sentRNN_loss)/self.batch_size\n",
    "            loss += sentRNN_loss * lambda_sent\n",
    "            loss_sent += sentRNN_loss\n",
    "\n",
    "       \n",
    "            topic = tf.nn.rnn_cell.LSTMStateTuple(sent_topic_vec[:, 0:512], sent_topic_vec[:, 512:])\n",
    "            word_state = (topic, topic)\n",
    "            for j in range(0, self.N_max):\n",
    "                if j > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                with tf.device('/cpu:0'):\n",
    "                    with tf.variable_scope('Wemb',reuse=tf.AUTO_REUSE):\n",
    "                        current_embed = tf.nn.embedding_lookup(self.Wemb, captions[:, i, j])\n",
    "                    \n",
    "                with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
    "                    # pdb.set_trace()\n",
    "                    word_output, word_state = self.word_LSTM(current_embed, word_state)\n",
    "\n",
    "                labels = tf.reshape(captions[:, i, j+1], [-1, 1])\n",
    "                indices = tf.reshape(tf.range(0, self.batch_size, 1), [-1, 1])\n",
    "                concated = tf.concat([indices, labels], 1)\n",
    "                onehot_labels = tf.sparse_to_dense(concated, tf.stack([self.batch_size, self.n_words]), 1.0, 0.0)\n",
    "\n",
    "                logit_words = tf.nn.xw_plus_b(word_output[:], self.embed_word_W, self.embed_word_b)\n",
    "                cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logit_words, labels=onehot_labels)\n",
    "                cross_entropy = cross_entropy * captions_masks[:, i, j]\n",
    "                loss_wordRNN = tf.reduce_sum(cross_entropy) / self.batch_size\n",
    "                loss += loss_wordRNN * lambda_word\n",
    "                loss_word += loss_wordRNN\n",
    "\n",
    "        return feats, num_distribution, captions, captions_masks, loss, loss_sent, loss_word\n",
    "\n",
    "    def generate_model(self):\n",
    "        feats = tf.placeholder(tf.float32, [1, self.num_boxes, self.feats_dim])\n",
    "        tmp_feats = tf.reshape(feats, [-1, self.feats_dim])\n",
    "\n",
    "        project_vec_all = tf.matmul(tmp_feats, self.regionPooling_W) + self.regionPooling_b\n",
    "        project_vec_all = tf.reshape(project_vec_all, [1, 50, self.project_dim])\n",
    "        project_vec = tf.reduce_max(project_vec_all, reduction_indices=1)\n",
    "\n",
    "        sent_state = self.sent_LSTM.zero_state(batch_size=1, dtype=tf.float32)\n",
    "\n",
    "        # save the generated paragraph to list, here I named generated_sents\n",
    "        generated_paragraph = []\n",
    "\n",
    "        # pred\n",
    "        pred_re = []\n",
    "\n",
    "        T_stop = tf.constant(0.5)\n",
    "\n",
    "        # Start build the generation model\n",
    "        print ('Start build the generation model: ')\n",
    "\n",
    "     \n",
    "        for i in range(0, self.S_max):\n",
    "            if i > 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "            sent_output, sent_state = self.sent_LSTM(project_vec, sent_state)\n",
    "\n",
    "        \n",
    "            with tf.name_scope('fc1'):\n",
    "                hidden1 = tf.nn.relu( tf.matmul(sent_output, self.fc1_W) + self.fc1_b )\n",
    "            with tf.name_scope('fc2'):\n",
    "                sent_topic_vec = tf.nn.relu( tf.matmul(hidden1, self.fc2_W) + self.fc2_b )\n",
    "\n",
    "            sentRNN_logistic_mu = tf.nn.xw_plus_b(sent_output, self.logistic_Theta_W, self.logistic_Theta_b)\n",
    "            pred = tf.nn.softmax(sentRNN_logistic_mu)\n",
    "            pred_re.append(pred)\n",
    "\n",
    "           \n",
    "            generated_sent = []\n",
    "\n",
    "          \n",
    "            topic = tf.nn.rnn_cell.LSTMStateTuple(sent_topic_vec[:, 0:512], sent_topic_vec[:, 512:])\n",
    "            word_state = (topic, topic)\n",
    "            # word RNN, unrolled to N_max time steps\n",
    "            for j in range(0, self.N_max):\n",
    "                if j > 0:\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                if j == 0:\n",
    "                    with tf.device('/cpu:0'):\n",
    "                    # get word embedding of BOS (index = 0)\n",
    "                        current_embed = tf.nn.embedding_lookup(self.Wemb, tf.zeros([1], dtype=tf.int64))\n",
    "\n",
    "                with tf.variable_scope('word_LSTM'):\n",
    "                    word_output, word_state = self.word_LSTM(current_embed, word_state)\n",
    "\n",
    "                logit_words = tf.nn.xw_plus_b(word_output, self.embed_word_W, self.embed_word_b)\n",
    "                max_prob_index = tf.argmax(logit_words, 1)[0]\n",
    "                generated_sent.append(max_prob_index)\n",
    "\n",
    "                with tf.device('/cpu:0'):\n",
    "                    current_embed = tf.nn.embedding_lookup(self.Wemb, max_prob_index)\n",
    "                    current_embed = tf.expand_dims(current_embed, 0)\n",
    "\n",
    "            generated_paragraph.append(generated_sent)\n",
    "        return feats, generated_paragraph, pred_re, sent_topic_vec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "def train():\n",
    "    ##############################################################################\n",
    "    # some preparing work\n",
    "    ##############################################################################\n",
    "    model_path = PREPROCESSED_PATH+'\\models_batch\\\\'\n",
    "    train_feats_path = PREPROCESSED_PATH+'\\genomedata\\im2p_train_output.h5'\n",
    "    if os.path.isfile(train_feats_path) and os.access(train_feats_path, os.R_OK):\n",
    "        train_output_file = h5py.File(train_feats_path, 'r')\n",
    "    else :\n",
    "        print(\"Either file is missing or is not readable\")\n",
    "        \n",
    "    train_feats = train_output_file.get('feats')\n",
    "    train_imgs_full_path_lists = open(PREPROCESSED_PATH+'\\imgs_train_path.txt').read().splitlines()\n",
    "    train_imgs_names = map(lambda x: os.path.basename(x).split('.')[0], train_imgs_full_path_lists)\n",
    "   # print(list(train_imgs_names))\n",
    "    model = RegionPooling_HierarchicalRNN(n_words = len(word2idx),\n",
    "                                          batch_size = batch_size,\n",
    "                                          num_boxes = num_boxes,\n",
    "                                          feats_dim = feats_dim,\n",
    "                                          project_dim = project_dim,\n",
    "                                          sentRNN_lstm_dim = sentRNN_lstm_dim,\n",
    "                                          sentRNN_FC_dim = sentRNN_FC_dim,\n",
    "                                          wordRNN_lstm_dim = wordRNN_lstm_dim,\n",
    "                                          S_max = S_max,\n",
    "                                          N_max = N_max,\n",
    "                                          word_embed_dim = word_embed_dim,\n",
    "                                          bias_init_vector = bias_init_vector)\n",
    "    tf_feats, tf_num_distribution, tf_captions_matrix, tf_captions_masks, tf_loss, tf_loss_sent, tf_loss_word = model.build_model()\n",
    "    with tf.Session() as sess:\n",
    "        print (\"start creating session\")\n",
    "        # saver = tf.train.Saver(max_to_keep=500, write_version=1)\n",
    "        with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate).minimize(tf_loss)\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        # when you want to train the model from the previously saved model\n",
    "        # how many models we want to save\n",
    "        saver = tf.train.Saver(max_to_keep=150)\n",
    "        # before TF v1, by cxp\n",
    "        # new_saver = tf.train.import_meta_graph('./models_batch/model-250.meta')\n",
    "        # print \"meta file imported\"\n",
    "        # model_file = tf.train.latest_checkpoint('./models_batch')  \n",
    "        # new_saver.restore(sess, model_file)\n",
    "        \n",
    "        try:\n",
    "            saver.restore(sess, './models_batch/model-20')\n",
    "            print (\"pretrained model loaded successfully\")\n",
    "        except:\n",
    "            print (\"fail to load pretrained model\")\n",
    "            pass\n",
    "        \n",
    "        all_vars = tf.trainable_variables()\n",
    "\n",
    "        # open a loss file to record the loss value\n",
    "        loss_fd = open('loss_batch.txt', 'a')\n",
    "        img2idx = {}\n",
    "        for idx, img in enumerate(train_imgs_names):\n",
    "            img2idx[img] = idx\n",
    "\n",
    "        loss_to_draw = []\n",
    "        plt_save_dir = './loss_imgs'\n",
    "        \n",
    "        for epoch in range(0, n_epochs):\n",
    "            loss_to_draw_epoch = []\n",
    "            random.shuffle(list(train_imgs_names))\n",
    "\n",
    "            for start, end in zip(range(0, len(list(train_imgs_names)), batch_size),\n",
    "                                  range(batch_size, len(list(train_imgs_names)), batch_size)):\n",
    "\n",
    "                start_time = time.time()\n",
    "\n",
    "                img_name = train_imgs_names[start:end]\n",
    "                current_feats_index = map(lambda x: img2idx[x], img_name)\n",
    "                current_feats = np.asarray( map(lambda x: train_feats[x], current_feats_index) )\n",
    "\n",
    "                current_num_distribution = np.asarray( map(lambda x: img2paragraph_modify[x][0], img_name) )\n",
    "                current_captions_matrix = np.asarray( map(lambda x: img2paragraph_modify[x][1], img_name) )\n",
    "\n",
    "                current_captions_masks = np.zeros( (current_captions_matrix.shape[0], current_captions_matrix.shape[1], current_captions_matrix.shape[2]) )\n",
    "                nonzeros = np.array( map(lambda each_matrix: np.array( map(lambda x: (x != 2).sum() + 1, each_matrix ) ), current_captions_matrix ) )\n",
    "                for i in range(batch_size):\n",
    "                    for ind, row in enumerate(current_captions_masks[i]):\n",
    "                        row[:(nonzeros[i, ind]-1)] = 1\n",
    "\n",
    "                _, loss_val, loss_sent, loss_word= sess.run(\n",
    "                                    [train_op, tf_loss, tf_loss_sent, tf_loss_word],\n",
    "                                    feed_dict={\n",
    "                                               tf_feats: current_feats,\n",
    "                                               tf_num_distribution: current_num_distribution,\n",
    "                                               tf_captions_matrix: current_captions_matrix,\n",
    "                                               tf_captions_masks: current_captions_masks\n",
    "                                    })\n",
    "\n",
    "                loss_to_draw_epoch.append(loss_val)\n",
    "\n",
    "                if idx % 1000 == 0:\n",
    "                    print ('idx: ', start, ' Epoch: ', epoch, ' loss: ', loss_val, ' loss_sent: ', loss_sent, ' loss_word: ', loss_word, \\\n",
    "                          ' Time cost: ', str((time.time() - start_time)))\n",
    "                loss_fd.write('epoch ' + str(epoch) + ' loss ' + str(loss_val))\n",
    "            \n",
    "            loss_to_draw.append(np.mean(loss_to_draw_epoch))\n",
    "\n",
    "            if np.mod(epoch, 10) == 0:\n",
    "                # draw loss curve every 10 epochs\n",
    "                plt_save_img_name = str(epoch) + '.png'\n",
    "                plt.plot(range(len(loss_to_draw)), loss_to_draw, color='g')\n",
    "                plt.grid(True)\n",
    "                plt.savefig(os.path.join(plt_save_dir, plt_save_img_name))\n",
    "            \n",
    "                # save weights every 20 epochs\n",
    "                if np.mod(epoch, 20) == 0:\n",
    "                    print (\"Epoch \", epoch, \" is done. Saving the model ...\")\n",
    "                    saver.save(sess, os.path.join(model_path, 'model'), global_step=epoch, write_meta_graph=False)\n",
    "        loss_fd.close()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start build model:\n",
      "naveen\n",
      "naveen\n",
      "naveen\n",
      "naveen\n",
      "naveen\n",
      "naveen\n",
      "start creating session\n",
      "INFO:tensorflow:Restoring parameters from ./models_batch/model-20\n",
      "fail to load pretrained model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naveen\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\naveen\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  is done. Saving the model ...\n",
      "Epoch  20  is done. Saving the model ...\n",
      "Epoch  40  is done. Saving the model ...\n",
      "Epoch  60  is done. Saving the model ...\n",
      "Epoch  80  is done. Saving the model ...\n",
      "Epoch  100  is done. Saving the model ...\n",
      "Epoch  120  is done. Saving the model ...\n",
      "Epoch  140  is done. Saving the model ...\n",
      "Epoch  160  is done. Saving the model ...\n",
      "Epoch  180  is done. Saving the model ...\n",
      "Epoch  200  is done. Saving the model ...\n",
      "Epoch  220  is done. Saving the model ...\n",
      "Epoch  240  is done. Saving the model ...\n",
      "Epoch  260  is done. Saving the model ...\n",
      "Epoch  280  is done. Saving the model ...\n",
      "Epoch  300  is done. Saving the model ...\n",
      "Epoch  320  is done. Saving the model ...\n",
      "Epoch  340  is done. Saving the model ...\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    start_time = time.time()\n",
    "    # change the model path according to your environment\n",
    "    model_path = './models_batch/model-500'\n",
    "\n",
    "    # It's very important to use Pandas to Series this idx2word dict\n",
    "    # After this operation, we can use list to extract the word at the same time\n",
    "    idx2word = pd.Series(np.load('./data/idx2word_batch.npy').tolist())\n",
    "\n",
    "    test_feats_path = './data/im2p_test_output.h5'\n",
    "    test_output_file = h5py.File(test_feats_path, 'r')\n",
    "    test_feats = test_output_file.get('feats')\n",
    "\n",
    "    test_imgs_full_path_lists = open('./densecap/imgs_test_order.txt').read().splitlines()\n",
    "    test_imgs_names = map(lambda x: os.path.basename(x).split('.')[0], test_imgs_full_path_lists)\n",
    "\n",
    "    # n_words, batch_size, num_boxes, feats_dim, project_dim, sentRNN_lstm_dim, sentRNN_FC_dim, wordRNN_lstm_dim, S_max, N_max\n",
    "    test_model = RegionPooling_HierarchicalRNN(n_words = len(word2idx),\n",
    "                                               batch_size = batch_size,\n",
    "                                               num_boxes = num_boxes,\n",
    "                                               feats_dim = feats_dim,\n",
    "                                               project_dim = project_dim,\n",
    "                                               sentRNN_lstm_dim = sentRNN_lstm_dim,\n",
    "                                               sentRNN_FC_dim = sentRNN_FC_dim,\n",
    "                                               wordRNN_lstm_dim = wordRNN_lstm_dim,\n",
    "                                               S_max = S_max,\n",
    "                                               N_max = N_max,\n",
    "                                               word_embed_dim = word_embed_dim,\n",
    "                                               bias_init_vector = bias_init_vector)\n",
    "\n",
    "    tf_feats, tf_generated_paragraph, tf_pred_re, tf_sent_topic_vectors = test_model.generate_model()\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, model_path)\n",
    "\n",
    "    img2idx = {}\n",
    "    for idx, img in enumerate(test_imgs_names):\n",
    "        img2idx[img] = idx\n",
    "\n",
    "    test_fd = open('HRNN_results.txt', 'w')\n",
    "    for idx, img_name in enumerate(test_imgs_names):\n",
    "        print (idx, img_name)\n",
    "        test_fd.write(img_name + '\\n')\n",
    "\n",
    "        each_paragraph = []\n",
    "        current_paragraph = \"\"\n",
    "\n",
    "        current_feats_index = img2idx[img_name]\n",
    "        current_feats = test_feats[current_feats_index]\n",
    "        current_feats = np.reshape(current_feats, [1, 50, 4096])\n",
    "\n",
    "        generated_paragraph_indexes, pred, sent_topic_vectors = sess.run(\n",
    "                                                                         [tf_generated_paragraph, tf_pred_re, tf_sent_topic_vectors],\n",
    "                                                                         feed_dict={\n",
    "                                                                             tf_feats: current_feats\n",
    "                                                                         })\n",
    "\n",
    "        #generated_paragraph = idx2word[generated_paragraph_indexes]\n",
    "        for sent_index in generated_paragraph_indexes:\n",
    "            each_sent = []\n",
    "            for word_index in sent_index:\n",
    "                each_sent.append(idx2word[word_index])\n",
    "            each_paragraph.append(each_sent)\n",
    "\n",
    "        for idx, each_sent in enumerate(each_paragraph):\n",
    "            # if the current sentence is the end sentence of the paragraph\n",
    "            # According to the probability distribution:\n",
    "            # CONTINUE: [1, 0]\n",
    "            # STOP    : [0, 1]\n",
    "            # So, if the first item of pred is less than the T_stop\n",
    "            # the generation process is break\n",
    "            if pred[idx][0][0] <= T_stop:\n",
    "                break\n",
    "            current_sent = ''\n",
    "            for each_word in each_sent:\n",
    "                current_sent += each_word + ' '\n",
    "            current_sent = current_sent.replace('<eos> ', '')\n",
    "            current_sent = current_sent.replace('<pad> ', '')\n",
    "            current_sent = current_sent + '.'\n",
    "            current_sent = current_sent.replace(' .', '.')\n",
    "            current_sent = current_sent.replace(' ,', ',')\n",
    "            current_paragraph +=current_sent\n",
    "            if idx != len(each_paragraph) - 1:\n",
    "                current_paragraph += ' '\n",
    "\n",
    "        test_fd.write(current_paragraph + '\\n')\n",
    "    test_fd.close()\n",
    "    print (\"Time cost: \" + str(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
