{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorpack.tfutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f3c6860ed96a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_moving_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margscope\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margscope\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munder_name_scope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_reuse_variable_scope\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'tensorpack.tfutils'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorpack.tfutils.summary import add_moving_summary\n",
    "from tensorpack.tfutils.argscope import argscope\n",
    "from tensorpack.tfutils.scope_utils import under_name_scope, auto_reuse_variable_scope\n",
    "from tensorpack.models import Conv2D, layer_register\n",
    "\n",
    "from model_box import clip_boxes\n",
    "from config import config as cfg\n",
    "\n",
    "\n",
    "@layer_register(log_shape=True)\n",
    "@auto_reuse_variable_scope\n",
    "def rpn_head(featuremap, channel, num_anchors):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        label_logits: fHxfWxNA\n",
    "        box_logits: fHxfWxNAx4\n",
    "    \"\"\"\n",
    "    with argscope(Conv2D, data_format='channels_first',\n",
    "                  kernel_initializer=tf.random_normal_initializer(stddev=0.01)):\n",
    "        hidden = Conv2D('conv0', featuremap, channel, 3, activation=tf.nn.relu)\n",
    "\n",
    "        label_logits = Conv2D('class', hidden, num_anchors, 1)\n",
    "        box_logits = Conv2D('box', hidden, 4 * num_anchors, 1)\n",
    "        # 1, NA(*4), im/16, im/16 (NCHW)\n",
    "\n",
    "        label_logits = tf.transpose(label_logits, [0, 2, 3, 1])  # 1xfHxfWxNA\n",
    "        label_logits = tf.squeeze(label_logits, 0)  # fHxfWxNA\n",
    "\n",
    "        shp = tf.shape(box_logits)  # 1x(NAx4)xfHxfW\n",
    "        box_logits = tf.transpose(box_logits, [0, 2, 3, 1])  # 1xfHxfWx(NAx4)\n",
    "        box_logits = tf.reshape(box_logits, tf.stack([shp[2], shp[3], num_anchors, 4]))  # fHxfWxNAx4\n",
    "    return label_logits, box_logits\n",
    "\n",
    "\n",
    "@under_name_scope()\n",
    "def rpn_losses(anchor_labels, anchor_boxes, label_logits, box_logits):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        anchor_labels: fHxfWxNA\n",
    "        anchor_boxes: fHxfWxNAx4, encoded\n",
    "        label_logits:  fHxfWxNA\n",
    "        box_logits: fHxfWxNAx4\n",
    "\n",
    "    Returns:\n",
    "        label_loss, box_loss\n",
    "    \"\"\"\n",
    "    with tf.device('/cpu:0'):\n",
    "        valid_mask = tf.stop_gradient(tf.not_equal(anchor_labels, -1))\n",
    "        pos_mask = tf.stop_gradient(tf.equal(anchor_labels, 1))\n",
    "        nr_valid = tf.stop_gradient(tf.count_nonzero(valid_mask, dtype=tf.int32), name='num_valid_anchor')\n",
    "        nr_pos = tf.identity(tf.count_nonzero(pos_mask, dtype=tf.int32), name='num_pos_anchor')\n",
    "        # nr_pos is guaranteed >0 in C4. But in FPN. even nr_valid could be 0.\n",
    "\n",
    "        valid_anchor_labels = tf.boolean_mask(anchor_labels, valid_mask)\n",
    "    valid_label_logits = tf.boolean_mask(label_logits, valid_mask)\n",
    "\n",
    "    with tf.name_scope('label_metrics'):\n",
    "        valid_label_prob = tf.nn.sigmoid(valid_label_logits)\n",
    "        summaries = []\n",
    "        with tf.device('/cpu:0'):\n",
    "            for th in [0.5, 0.2, 0.1]:\n",
    "                valid_prediction = tf.cast(valid_label_prob > th, tf.int32)\n",
    "                nr_pos_prediction = tf.reduce_sum(valid_prediction, name='num_pos_prediction')\n",
    "                pos_prediction_corr = tf.count_nonzero(\n",
    "                    tf.logical_and(\n",
    "                        valid_label_prob > th,\n",
    "                        tf.equal(valid_prediction, valid_anchor_labels)),\n",
    "                    dtype=tf.int32)\n",
    "                placeholder = 0.5   # A small value will make summaries appear lower.\n",
    "                recall = tf.to_float(tf.truediv(pos_prediction_corr, nr_pos))\n",
    "                recall = tf.where(tf.equal(nr_pos, 0), placeholder, recall, name='recall_th{}'.format(th))\n",
    "                precision = tf.to_float(tf.truediv(pos_prediction_corr, nr_pos_prediction))\n",
    "                precision = tf.where(tf.equal(nr_pos_prediction, 0),\n",
    "                                     placeholder, precision, name='precision_th{}'.format(th))\n",
    "                summaries.extend([precision, recall])\n",
    "        add_moving_summary(*summaries)\n",
    "\n",
    "    # Per-level loss summaries in FPN may appear lower due to the use of a small placeholder.\n",
    "    # But the total RPN loss will be fine.  TODO make the summary op smarter\n",
    "    placeholder = 0.\n",
    "    label_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=tf.to_float(valid_anchor_labels), logits=valid_label_logits)\n",
    "    label_loss = tf.reduce_sum(label_loss) * (1. / cfg.RPN.BATCH_PER_IM)\n",
    "    label_loss = tf.where(tf.equal(nr_valid, 0), placeholder, label_loss, name='label_loss')\n",
    "\n",
    "    pos_anchor_boxes = tf.boolean_mask(anchor_boxes, pos_mask)\n",
    "    pos_box_logits = tf.boolean_mask(box_logits, pos_mask)\n",
    "    delta = 1.0 / 9\n",
    "    box_loss = tf.losses.huber_loss(\n",
    "        pos_anchor_boxes, pos_box_logits, delta=delta,\n",
    "        reduction=tf.losses.Reduction.SUM) / delta\n",
    "    box_loss = box_loss * (1. / cfg.RPN.BATCH_PER_IM)\n",
    "    box_loss = tf.where(tf.equal(nr_pos, 0), placeholder, box_loss, name='box_loss')\n",
    "\n",
    "    add_moving_summary(label_loss, box_loss, nr_valid, nr_pos)\n",
    "    return label_loss, box_loss\n",
    "\n",
    "\n",
    "@under_name_scope()\n",
    "def generate_rpn_proposals(boxes, scores, img_shape,\n",
    "                           pre_nms_topk, post_nms_topk=None):\n",
    "    \"\"\"\n",
    "    Sample RPN proposals by the following steps:\n",
    "    1. Pick top k1 by scores\n",
    "    2. NMS them\n",
    "    3. Pick top k2 by scores. Default k2 == k1, i.e. does not filter the NMS output.\n",
    "\n",
    "    Args:\n",
    "        boxes: nx4 float dtype, the proposal boxes. Decoded to floatbox already\n",
    "        scores: n float, the logits\n",
    "        img_shape: [h, w]\n",
    "        pre_nms_topk, post_nms_topk (int): See above.\n",
    "\n",
    "    Returns:\n",
    "        boxes: kx4 float\n",
    "        scores: k logits\n",
    "    \"\"\"\n",
    "    assert boxes.shape.ndims == 2, boxes.shape\n",
    "    if post_nms_topk is None:\n",
    "        post_nms_topk = pre_nms_topk\n",
    "\n",
    "    topk = tf.minimum(pre_nms_topk, tf.size(scores))\n",
    "    topk_scores, topk_indices = tf.nn.top_k(scores, k=topk, sorted=False)\n",
    "    topk_boxes = tf.gather(boxes, topk_indices)\n",
    "    topk_boxes = clip_boxes(topk_boxes, img_shape)\n",
    "\n",
    "    topk_boxes_x1y1x2y2 = tf.reshape(topk_boxes, (-1, 2, 2))\n",
    "    topk_boxes_x1y1, topk_boxes_x2y2 = tf.split(topk_boxes_x1y1x2y2, 2, axis=1)\n",
    "    # nx1x2 each\n",
    "    wbhb = tf.squeeze(topk_boxes_x2y2 - topk_boxes_x1y1, axis=1)\n",
    "    valid = tf.reduce_all(wbhb > cfg.RPN.MIN_SIZE, axis=1)  # n,\n",
    "    topk_valid_boxes_x1y1x2y2 = tf.boolean_mask(topk_boxes_x1y1x2y2, valid)\n",
    "    topk_valid_scores = tf.boolean_mask(topk_scores, valid)\n",
    "\n",
    "    # TODO not needed\n",
    "    topk_valid_boxes_y1x1y2x2 = tf.reshape(\n",
    "        tf.reverse(topk_valid_boxes_x1y1x2y2, axis=[2]),\n",
    "        (-1, 4), name='nms_input_boxes')\n",
    "    nms_indices = tf.image.non_max_suppression(\n",
    "        topk_valid_boxes_y1x1y2x2,\n",
    "        topk_valid_scores,\n",
    "        max_output_size=post_nms_topk,\n",
    "        iou_threshold=cfg.RPN.PROPOSAL_NMS_THRESH)\n",
    "\n",
    "    topk_valid_boxes = tf.reshape(topk_valid_boxes_x1y1x2y2, (-1, 4))\n",
    "    proposal_boxes = tf.gather(topk_valid_boxes, nms_indices)\n",
    "    proposal_scores = tf.gather(topk_valid_scores, nms_indices)\n",
    "    tf.sigmoid(proposal_scores, name='probs')  # for visualization\n",
    "    return tf.stop_gradient(proposal_boxes, name='boxes'), tf.stop_gradient(proposal_scores, name='scores')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
